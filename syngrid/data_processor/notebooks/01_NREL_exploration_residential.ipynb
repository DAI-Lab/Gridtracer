{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define the input and output paths\n",
    "input_file = Path(\"/Users/magic-rabbit/Documents/MA-data/NREL_Residential_typology.tsv\")\n",
    "output_dir = Path(\"county_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Process the file in chunks\n",
    "chunk_size = 100000\n",
    "processed_counties = set()\n",
    "\n",
    "logger.info(\"Starting to process the TSV file...\")\n",
    "\n",
    "for chunk in pd.read_csv(input_file, sep=\"\\t\", chunksize=chunk_size):\n",
    "    # Convert county to string for consistent naming\n",
    "    chunk['in.county'] = chunk['in.county'].astype(str)\n",
    "    logger.info(chunk)\n",
    "    \n",
    "    # Process each county in the current chunk\n",
    "    for county_id, group in chunk.groupby('in.county'):\n",
    "        if county_id not in processed_counties:\n",
    "            output_file = output_dir / f\"county_{county_id}.parquet\"\n",
    "            group.to_parquet(output_file, index=False)\n",
    "            processed_counties.add(county_id)\n",
    "            logger.info(f\"Saved data for county {county_id}\")\n",
    "    \n",
    "    # Optional: Add a progress indicator\n",
    "    logger.info(f\"Processed {len(processed_counties)} unique counties so far\")\n",
    "\n",
    "logger.info(\"Finished processing all counties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load a single county's data\n",
    "import pandas as pd\n",
    "\n",
    "# Load one county file (using G0100370 as an example)\n",
    "county_data = pd.read_parquet(\"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/notebooks/county_data/county_G2002070.parquet\")\n",
    "\n",
    "# Display basic information about the data\n",
    "print(\"Data shape:\", county_data.shape)\n",
    "print(\"\\nColumns:\", county_data.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(county_data.head())\n",
    "\n",
    "\n",
    "columns_to_show = [\n",
    "    'in.county',\n",
    "    'in.state',\n",
    "    'in.puma',\n",
    "    'in.ahs_region',\n",
    "    'in.american_housing_survey_region',\n",
    "    'in.resstock_county_id',\n",
    "    'in.resstock_puma_id',\n",
    "    'in.nhgis_county_gisjoin',\n",
    "    'in.nhgis_puma_gisjoin',\n",
    "    'in.state_name'\n",
    "]\n",
    "\n",
    "# Display the first 5 random rows of the selected columns\n",
    "print(county_data[columns_to_show].sample(n=3, random_state=1))\n",
    "\n",
    "# Show some basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "display(county_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define the input and output paths\n",
    "input_file = Path(\"/Users/magic-rabbit/Library/Mobile Documents/com~apple~CloudDocs/01_University/06_MIT_Stay/Master_Thesis/Data/NREL_Residential_typology.tsv\")\n",
    "output_dir = Path(\"county_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Process the file in chunks\n",
    "chunk_size = 100000\n",
    "processed_counties = set()\n",
    "\n",
    "logger.info(\"Starting to process the TSV file...\")\n",
    "\n",
    "for chunk in pd.read_csv(input_file, sep=\"\\t\", chunksize=chunk_size):\n",
    "    # Convert county to string for consistent naming\n",
    "    chunk['in.county'] = chunk['in.county'].astype(str)\n",
    "    \n",
    "    # Process each county in the current chunk\n",
    "    for county_id, group in chunk.groupby('in.county'):\n",
    "        if county_id not in processed_counties:\n",
    "            output_file = output_dir / f\"county_{county_id}.parquet\"\n",
    "            group.to_parquet(output_file, index=False)\n",
    "            processed_counties.add(county_id)\n",
    "            logger.info(f\"Saved data for county {county_id}\")\n",
    "    \n",
    "    # Optional: Add a progress indicator\n",
    "    logger.info(f\"Processed {len(processed_counties)} unique counties so far\")\n",
    "\n",
    "logger.info(\"Finished processing all counties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
