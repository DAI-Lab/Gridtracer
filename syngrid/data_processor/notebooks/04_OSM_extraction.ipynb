{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from syngrid.data_processor.processing.building_processor import BuildingHeuristicsProcessor\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Building results: \n",
    "\n",
    "buildings_filepath = '/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/MA/Middlesex_County/Cambridge_city/OSM/buildings.geojson'\n",
    "gdf = gpd.read_file(buildings_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_geometry_types(gdf):\n",
    "        \n",
    "    if gdf is None or len(gdf) == 0:\n",
    "        return {\"Empty GeoDataFrame\": 0}\n",
    "        \n",
    "    # Count by geometry type\n",
    "    type_counts = gdf.geometry.geom_type.value_counts().to_dict()\n",
    "    \n",
    "    # Log the results\n",
    "    for geom_type, count in type_counts.items():\n",
    "        print(f\"Found {count} features of type {geom_type}\")\n",
    "        \n",
    "    return type_counts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import numpy as np\n",
    "\n",
    "def plot_mixed_geometries(gdf, title=\"Points and Polygons\", figsize=(12, 10), \n",
    "                         point_color='red', polygon_color='blue', alpha=0.6, \n",
    "                         basemap=True, point_size=50):\n",
    "    \"\"\"\n",
    "    Plot points and polygons from a GeoDataFrame in different colors on a map.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Input GeoDataFrame with mixed geometry types\n",
    "    title : str\n",
    "        Plot title\n",
    "    figsize : tuple\n",
    "        Figure size as (width, height)\n",
    "    point_color : str\n",
    "        Color for point geometries\n",
    "    polygon_color : str\n",
    "        Color for polygon geometries\n",
    "    alpha : float\n",
    "        Transparency level (0-1)\n",
    "    basemap : bool\n",
    "        Whether to add a contextily basemap\n",
    "    point_size : int\n",
    "        Size of point markers\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig, ax : matplotlib figure and axis objects\n",
    "    \"\"\"\n",
    "    # Ensure we have a valid GeoDataFrame\n",
    "    if gdf is None or len(gdf) == 0:\n",
    "        print(\"Empty GeoDataFrame provided\")\n",
    "        return None, None\n",
    "    \n",
    "    # Ensure the GeoDataFrame is in a Web Mercator projection for contextily basemap\n",
    "    if basemap and gdf.crs != \"EPSG:3857\":\n",
    "        gdf_web_mercator = gdf.to_crs(\"EPSG:3857\")\n",
    "    else:\n",
    "        gdf_web_mercator = gdf.copy()\n",
    "        \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Separate points and polygons\n",
    "    points = gdf_web_mercator[gdf_web_mercator.geometry.geom_type == 'Point']\n",
    "    polygons = gdf_web_mercator[gdf_web_mercator.geometry.geom_type.isin(['Polygon', 'MultiPolygon'])]\n",
    "    \n",
    "    # Get count of each type for the legend\n",
    "    points_count = len(points)\n",
    "    polygon_count = len(polygons)\n",
    "    \n",
    "    # Plot the data\n",
    "    if not polygons.empty:\n",
    "        polygons.plot(ax=ax, color=polygon_color, alpha=alpha, label=f'Polygons ({polygon_count})')\n",
    "    \n",
    "    if not points.empty:\n",
    "        points.plot(ax=ax, color=point_color, markersize=point_size, alpha=alpha, label=f'Points ({points_count})')\n",
    "    \n",
    "    # Add a basemap if requested\n",
    "    if basemap:\n",
    "        cx.add_basemap(ax, source=cx.providers.OpenStreetMap.Mapnik)\n",
    "    \n",
    "    # Set plot title and add legend\n",
    "    ax.set_title(title, fontsize=15)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    # Remove axis labels for map\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add text showing which points are inside polygons\n",
    "    if not points.empty and not polygons.empty:\n",
    "        # Count points inside any polygon\n",
    "        points_inside = 0\n",
    "        for point in points.geometry:\n",
    "            if any(polygon.contains(point) for polygon in polygons.geometry):\n",
    "                points_inside += 1\n",
    "        \n",
    "        percent_inside = (points_inside / len(points)) * 100 if len(points) > 0 else 0\n",
    "        plt.figtext(0.5, 0.01, \n",
    "                   f\"{points_inside} of {len(points)} points ({percent_inside:.1f}%) are inside polygons\",\n",
    "                   ha=\"center\", fontsize=12, bbox={\"facecolor\":\"white\", \"alpha\":0.7, \"pad\":5})\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Example usage:\n",
    "fig, ax = plot_mixed_geometries(gdf, title=\"Buildings and POIs\")\n",
    "plt.show()\n",
    "\n",
    "count_geometry_types(gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "def explore_geodataframe(gdf, exclude_cols=None, max_categories=10, figsize=(18, 12)):\n",
    "    \"\"\"\n",
    "    Comprehensive exploration of a GeoDataFrame, analyzing categorical distributions and null values.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        The GeoDataFrame to analyze\n",
    "    exclude_cols : list\n",
    "        List of columns to exclude from analysis (e.g., ['geometry', 'id', 'element'])\n",
    "    max_categories : int\n",
    "        Maximum number of categories to display in distribution plots\n",
    "    figsize : tuple\n",
    "        Figure size for plots\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = ['geometry', 'id', 'element', 'index']\n",
    "    \n",
    "    # Create a copy without excluded columns\n",
    "    df_analysis = gdf.drop(columns=[col for col in exclude_cols if col in gdf.columns])\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"Dataset has {len(gdf)} rows and {len(df_analysis.columns)} columns (excluding {len(exclude_cols)} specified columns)\")\n",
    "    \n",
    "    # 1. Null values analysis\n",
    "    print(\"\\n--- NULL VALUES ANALYSIS ---\")\n",
    "    null_counts = df_analysis.isnull().sum().sort_values(ascending=False)\n",
    "    null_percent = (null_counts / len(df_analysis) * 100).round(2)\n",
    "    null_df = pd.DataFrame({'Count': null_counts, 'Percent': null_percent})\n",
    "\n",
    "    # Only show columns with nulls\n",
    "    null_df = null_df[null_df['Count'] > 0]\n",
    "    if len(null_df) > 0:\n",
    "        display(null_df)\n",
    "        \n",
    "        # Calculate plot height based on number of columns (at least 8 inches tall)\n",
    "        plot_height = max(8, len(null_df) * 0.4)\n",
    "        \n",
    "        # Visualize null values with a much taller plot\n",
    "        plt.figure(figsize=(figsize[0], plot_height))\n",
    "        \n",
    "        # Create the horizontal bar plot\n",
    "        bars = plt.barh(null_df.index, null_df['Percent'], color='skyblue')\n",
    "        \n",
    "        # Add percentage labels to the right of each bar\n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            plt.text(width + 1, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{width:.1f}%', \n",
    "                    va='center', fontweight='bold')\n",
    "        \n",
    "        plt.title('Percentage of NULL Values by Column', fontsize=14)\n",
    "        plt.xlabel('Percent (%)', fontsize=12)\n",
    "        plt.xlim(0, min(100, null_df['Percent'].max() * 1.15))  # Add some space for labels\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No NULL values found in any column!\")\n",
    "    \n",
    "    # 2. Categorical columns analysis\n",
    "    categorical_cols = df_analysis.select_dtypes(include=['object', 'category']).columns\n",
    "    print(f\"\\n--- CATEGORICAL COLUMNS ANALYSIS ({len(categorical_cols)} columns) ---\")\n",
    "    \n",
    "    results = {}\n",
    "    if len(categorical_cols) > 0:\n",
    "        for col in categorical_cols:\n",
    "            # Skip if column has all nulls\n",
    "            if df_analysis[col].isnull().all():\n",
    "                results[col] = {'values': None, 'distribution': None}\n",
    "                continue\n",
    "                \n",
    "            # Get value counts and non-null percentage\n",
    "            val_counts = df_analysis[col].value_counts().reset_index()\n",
    "            val_counts.columns = [col, 'Count']\n",
    "            val_counts['Percent'] = (val_counts['Count'] / len(df_analysis) * 100).round(2)\n",
    "            \n",
    "            # Calculate fill rate\n",
    "            non_null_percent = (df_analysis[col].count() / len(df_analysis) * 100).round(2)\n",
    "            \n",
    "            # Store in results\n",
    "            results[col] = {\n",
    "                'values': val_counts,\n",
    "                'non_null_percent': non_null_percent,\n",
    "                'unique_values': df_analysis[col].nunique()\n",
    "            }\n",
    "            \n",
    "            # Display information\n",
    "            print(f\"\\nColumn: {col}\")\n",
    "            print(f\"Fill rate: {non_null_percent}% ({df_analysis[col].count()} / {len(df_analysis)})\")\n",
    "            print(f\"Unique values: {df_analysis[col].nunique()}\")\n",
    "            \n",
    "            # Display top categories if not too many\n",
    "            if df_analysis[col].nunique() < 50:\n",
    "                # Limit to top categories for display\n",
    "                display(val_counts.head(max_categories))\n",
    "                \n",
    "                # Plot if not too many categories\n",
    "                if df_analysis[col].nunique() <= max_categories:\n",
    "                    plt.figure(figsize=(figsize[0]//2, figsize[1]//3))\n",
    "                    sns.barplot(x='Count', y=col, data=val_counts)\n",
    "                    plt.title(f'Distribution of {col}')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "            else:\n",
    "                print(f\"Too many unique values ({df_analysis[col].nunique()}) to display\")\n",
    "    \n",
    "    # 3. Numeric columns analysis\n",
    "    numeric_cols = df_analysis.select_dtypes(include=['int64', 'float64']).columns\n",
    "    print(f\"\\n--- NUMERIC COLUMNS ANALYSIS ({len(numeric_cols)} columns) ---\")\n",
    "    \n",
    "    if len(numeric_cols) > 0:\n",
    "        # Display summary statistics\n",
    "        stats = df_analysis[numeric_cols].describe().T\n",
    "        stats['fill_rate'] = (df_analysis[numeric_cols].count() / len(df_analysis) * 100).round(2)\n",
    "        display(stats)\n",
    "        \n",
    "        # Plot distributions\n",
    "        if len(numeric_cols) > 0:\n",
    "            fig, axes = plt.subplots(nrows=min(len(numeric_cols), 3), ncols=1, figsize=figsize)\n",
    "            if len(numeric_cols) == 1:\n",
    "                axes = [axes]\n",
    "                \n",
    "            for i, col in enumerate(numeric_cols[:3]):  # Limit to 3 plots\n",
    "                try:\n",
    "                    sns.histplot(df_analysis[col].dropna(), kde=True, ax=axes[i])\n",
    "                    axes[i].set_title(f'Distribution of {col}')\n",
    "                except:\n",
    "                    print(f\"Could not plot {col}\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    # 4. OSM tag analysis (for OSM specific data)\n",
    "    osm_tags = [col for col in df_analysis.columns if ':' in col]\n",
    "    if len(osm_tags) > 0:\n",
    "        print(f\"\\n--- OSM TAGS ANALYSIS ({len(osm_tags)} tags) ---\")\n",
    "        # Display the top OSM tags by presence\n",
    "        tag_counts = pd.Series({tag: df_analysis[tag].count() for tag in osm_tags})\n",
    "        tag_percent = (tag_counts / len(df_analysis) * 100).round(2)\n",
    "        tag_df = pd.DataFrame({'Count': tag_counts, 'Percent': tag_percent}).sort_values('Count', ascending=False)\n",
    "        \n",
    "        display(tag_df.head(20))\n",
    "        \n",
    "        # Plot top 15 tags\n",
    "        plt.figure(figsize=(figsize[0], figsize[1]//2))\n",
    "        sns.barplot(x='Percent', y=tag_df.head(15).index, data=tag_df.head(15))\n",
    "        plt.title('Top 15 OSM Tags by Presence')\n",
    "        plt.xlabel('Percent (%)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    # 5. Geometry type analysis\n",
    "    print(\"\\n--- GEOMETRY TYPE ANALYSIS ---\")\n",
    "    geom_counts = gdf.geometry.geom_type.value_counts()\n",
    "    geom_percent = (geom_counts / len(gdf) * 100).round(2)\n",
    "    geom_df = pd.DataFrame({'Count': geom_counts, 'Percent': geom_percent})\n",
    "    display(geom_df)\n",
    "    \n",
    "    # Plot geometry types\n",
    "    plt.figure(figsize=(figsize[0]//2, figsize[1]//3))\n",
    "    plt.pie(geom_df['Count'], labels=geom_df.index, autopct='%1.1f%%')\n",
    "    plt.title('Geometry Types')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Building type analysis (if applicable)\n",
    "    if 'building' in df_analysis.columns:\n",
    "        print(\"\\n--- BUILDING TYPE ANALYSIS ---\")\n",
    "        bldg_counts = df_analysis['building'].value_counts().reset_index()\n",
    "        bldg_counts.columns = ['building', 'Count']\n",
    "        bldg_counts['Percent'] = (bldg_counts['Count'] / df_analysis['building'].count() * 100).round(2)\n",
    "        \n",
    "        display(bldg_counts.head(max_categories))\n",
    "        \n",
    "        # Plot building types\n",
    "        if len(bldg_counts) <= max_categories:\n",
    "            plt.figure(figsize=(figsize[0], figsize[1]//2))\n",
    "            sns.barplot(x='Count', y='building', data=bldg_counts)\n",
    "            plt.title('Building Types')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# # Example usage:\n",
    "# analysis_results = explore_geodataframe(gdf, exclude_cols=['geometry', 'id', 'element'])\n",
    "\n",
    "\n",
    "# Transform the gdf to a dataframe by dropping the geometry column\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Drop geometry column to avoid issues\n",
    "df = gdf.drop(columns='geometry')\n",
    "\n",
    "# Generate the profile report\n",
    "profile = ProfileReport(df, title=\"Profiling Report\", explorative=True)\n",
    "profile.to_file(\"profiling_report.html\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtered = gdf[gdf['amenity'].notna()].copy()\n",
    "gdf_filtered = gdf_filtered[gdf_filtered['building']=='yes'].copy()\n",
    "\n",
    "# Columns to display\n",
    "# We'll only try to display columns that actually exist in gdf_filtered\n",
    "cols_to_show_base = ['amenity', 'building', 'shop', 'office']\n",
    "cols_to_show_existing = [col for col in cols_to_show_base if col in gdf_filtered.columns]\n",
    "print(gdf_filtered[cols_to_show_existing])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrosm import OSM\n",
    "import geopandas as gpd\n",
    "from pyrosm import get_data\n",
    "fp = get_data(\"Massachusetts\")\n",
    "bounding_box = gpd.read_file(\"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/MA/Middlesex_County/Cambridge_city/CENSUS/target_region_boundary.geojson\")\n",
    "polygon = bounding_box.geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OSM parser object\n",
    "import time \n",
    "start_time = time.time()\n",
    "osm = OSM(fp,bounding_box=polygon)\n",
    "buildings = osm.get_buildings()\n",
    "buildings.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = buildings.plot(column=\"building\", figsize=(12,12), legend=True, legend_kwds=dict(loc='upper left', ncol=3, bbox_to_anchor=(1, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_filter = {'amenity': True}\n",
    "pois = osm.get_pois(custom_filter=custom_filter)\n",
    "\n",
    "# Gather info about POI type (combines the tag info from \"amenity\" and \"shop\")\n",
    "pois[\"poi_type\"] = pois[\"amenity\"]\n",
    "\n",
    "# Plot\n",
    "ax = pois.plot(column='poi_type', markersize=3, figsize=(12,12), legend=True, legend_kwds=dict(loc='upper left', ncol=5, bbox_to_anchor=(1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse = osm.get_landuse()\n",
    "landuse.plot(column='landuse', legend=True, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = osm.get_network(network_type=\"all\")\n",
    "network.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "from shapely.errors import GEOSException # Import for handling potential geometry errors\n",
    "\n",
    "buildings = gpd.read_file(\"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/unassigned_buildings.geojson\")\n",
    "def plot_buildings_with_floor_area(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    floor_area_column: str = 'floor_area',\n",
    "    title: str = \"Building Footprints with Floor Area\",\n",
    "    figsize: tuple = (15, 15),\n",
    "    polygon_color: str = 'blue',\n",
    "    alpha: float = 0.5,\n",
    "    basemap_provider: cx.providers = cx.providers.OpenStreetMap.Mapnik,\n",
    "    label_fontsize: int = 8,\n",
    "    label_color: str = 'black',\n",
    "    label_background_alpha: float = 0.7,\n",
    "    label_bbox_pad: float = 0.2\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots building polygons from a GeoDataFrame on a contextily basemap,\n",
    "    labeling each building with its floor area.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Input GeoDataFrame with building geometries and a floor area column.\n",
    "        Must have a valid CRS.\n",
    "    floor_area_column : str, optional\n",
    "        The name of the column in gdf containing the floor area values.\n",
    "        Defaults to 'floor_area'.\n",
    "    title : str, optional\n",
    "        Plot title. Defaults to \"Building Footprints with Floor Area\".\n",
    "    figsize : tuple, optional\n",
    "        Figure size as (width, height). Defaults to (15, 15).\n",
    "    polygon_color : str, optional\n",
    "        Color for polygon geometries. Defaults to 'blue'.\n",
    "    alpha : float, optional\n",
    "        Transparency level for polygons (0-1). Defaults to 0.5.\n",
    "    basemap_provider : contextily.providers object, optional\n",
    "        The contextily basemap provider.\n",
    "        Defaults to cx.providers.OpenStreetMap.Mapnik.\n",
    "    label_fontsize : int, optional\n",
    "        Font size for the floor area labels. Defaults to 8.\n",
    "    label_color : str, optional\n",
    "        Color for the floor area labels. Defaults to 'black'.\n",
    "    label_background_alpha : float, optional\n",
    "        Alpha for the label background box (0-1). Defaults to 0.7.\n",
    "    label_bbox_pad : float, optional\n",
    "        Padding for the label background box. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Displays the plot.\n",
    "    \"\"\"\n",
    "    if not isinstance(gdf, gpd.GeoDataFrame):\n",
    "        print(\"Input must be a GeoDataFrame.\")\n",
    "        return\n",
    "    if gdf.empty:\n",
    "        print(\"GeoDataFrame is empty. Nothing to plot.\")\n",
    "        return\n",
    "    \n",
    "    if floor_area_column not in gdf.columns:\n",
    "        print(f\"Column '{floor_area_column}' not found in GeoDataFrame.\")\n",
    "        return\n",
    "    if gdf.crs is None:\n",
    "        print(\"GeoDataFrame must have a Coordinate Reference System (CRS) defined.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the GeoDataFrame is in Web Mercator projection for contextily\n",
    "    gdf_web_mercator = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot polygons\n",
    "    gdf_web_mercator.plot(\n",
    "        ax=ax,\n",
    "        color=polygon_color,\n",
    "        alpha=alpha,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "\n",
    "    # Add basemap\n",
    "    try:\n",
    "        cx.add_basemap(ax, source=basemap_provider, zoom='auto')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not add basemap: {e}. Plotting without it.\")\n",
    "\n",
    "\n",
    "    # Add floor area labels\n",
    "    for idx, row in gdf_web_mercator.iterrows():\n",
    "        try:\n",
    "            # Use a representative point for labeling, robust to invalid polygons\n",
    "            point_for_label = row.geometry.representative_point()\n",
    "            if point_for_label.is_empty: # Check if representative_point is valid\n",
    "                 # Fallback to centroid if representative_point is empty (should be rare)\n",
    "                point_for_label = row.geometry.centroid\n",
    "            \n",
    "            if not point_for_label.is_empty: # Final check before plotting text\n",
    "                floor_area = row[floor_area_column]\n",
    "                label = f\"{floor_area:,.0f} m²\" if pd.notnull(floor_area) else \"N/A\"\n",
    "                \n",
    "                ax.text(\n",
    "                    point_for_label.x,\n",
    "                    point_for_label.y,\n",
    "                    label,\n",
    "                    fontsize=label_fontsize,\n",
    "                    color=label_color,\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    bbox=dict(\n",
    "                        boxstyle='round,pad=' + str(label_bbox_pad),\n",
    "                        fc='white',\n",
    "                        alpha=label_background_alpha,\n",
    "                        ec='none' # No edge color for bbox\n",
    "                    )\n",
    "                )\n",
    "        except GEOSException:\n",
    "            print(f\"Warning: Could not generate a representative point for geometry at index {idx}. Skipping label.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while labeling geometry at index {idx}: {e}\")\n",
    "\n",
    "\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Randomly sample ten rows from gpd:\n",
    "samples = buildings.sample(n=100, random_state=1)\n",
    "\n",
    "plot_buildings_with_floor_area(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Blocks and buildigns itnersection: \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "from shapely.errors import GEOSException # Import for handling potential geometry errors\n",
    "\n",
    "# Load the data\n",
    "unassigned_buildings = gpd.read_file(\"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/unassigned_buildings.geojson\")\n",
    "census_blocks = gpd.read_file(\"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/MA/Middlesex_County/Cambridge_city/CENSUS/target_region_blocks.geojson\")\n",
    "\n",
    "def plot_unassigned_buildings_with_census_blocks(\n",
    "    buildings_gdf: gpd.GeoDataFrame,\n",
    "    census_blocks_gdf: gpd.GeoDataFrame,\n",
    "    title: str = \"Unassigned Buildings and Census Blocks\",\n",
    "    figsize: tuple = (15, 15),\n",
    "    block_color: str = 'red',\n",
    "    building_color: str = 'blue',\n",
    "    block_alpha: float = 0.3,\n",
    "    building_alpha: float = 0.8,\n",
    "    basemap_provider: cx.providers = cx.providers.OpenStreetMap.Mapnik\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots census blocks and unassigned buildings on a contextily basemap to visualize\n",
    "    spatial relationships and identify why buildings couldn't be assigned to blocks.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    buildings_gdf : GeoDataFrame\n",
    "        GeoDataFrame with unassigned building geometries.\n",
    "    census_blocks_gdf : GeoDataFrame\n",
    "        GeoDataFrame with census block geometries.\n",
    "    title : str, optional\n",
    "        Plot title. Defaults to \"Unassigned Buildings and Census Blocks\".\n",
    "    figsize : tuple, optional\n",
    "        Figure size as (width, height). Defaults to (15, 15).\n",
    "    block_color : str, optional\n",
    "        Color for census block polygons. Defaults to 'red'.\n",
    "    building_color : str, optional\n",
    "        Color for building polygons. Defaults to 'blue'.\n",
    "    block_alpha : float, optional\n",
    "        Transparency level for census blocks (0-1). Defaults to 0.3.\n",
    "    building_alpha : float, optional\n",
    "        Transparency level for buildings (0-1). Defaults to 0.8.\n",
    "    basemap_provider : contextily.providers object, optional\n",
    "        The contextily basemap provider.\n",
    "        Defaults to cx.providers.OpenStreetMap.Mapnik.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Displays the plot.\n",
    "    \"\"\"\n",
    "    if not isinstance(buildings_gdf, gpd.GeoDataFrame):\n",
    "        print(\"Buildings input must be a GeoDataFrame.\")\n",
    "        return\n",
    "    if not isinstance(census_blocks_gdf, gpd.GeoDataFrame):\n",
    "        print(\"Census blocks input must be a GeoDataFrame.\")\n",
    "        return\n",
    "    if buildings_gdf.empty:\n",
    "        print(\"Buildings GeoDataFrame is empty. Nothing to plot.\")\n",
    "        return\n",
    "    if census_blocks_gdf.empty:\n",
    "        print(\"Census blocks GeoDataFrame is empty. Nothing to plot.\")\n",
    "        return\n",
    "    \n",
    "    if buildings_gdf.crs is None:\n",
    "        print(\"Buildings GeoDataFrame must have a Coordinate Reference System (CRS) defined.\")\n",
    "        return\n",
    "    if census_blocks_gdf.crs is None:\n",
    "        print(\"Census blocks GeoDataFrame must have a Coordinate Reference System (CRS) defined.\")\n",
    "        return\n",
    "\n",
    "    # Ensure both GeoDataFrames are in Web Mercator projection for contextily\n",
    "    buildings_web_mercator = buildings_gdf.to_crs(epsg=3857)\n",
    "    blocks_web_mercator = census_blocks_gdf.to_crs(epsg=3857)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot census blocks first (background layer)\n",
    "    blocks_web_mercator.plot(\n",
    "        ax=ax,\n",
    "        color=block_color,\n",
    "        alpha=block_alpha,\n",
    "        edgecolor='darkred',\n",
    "        linewidth=1.0,\n",
    "        label='Census Blocks'\n",
    "    )\n",
    "\n",
    "    # Plot buildings on top\n",
    "    buildings_web_mercator.plot(\n",
    "        ax=ax,\n",
    "        color=building_color,\n",
    "        alpha=building_alpha,\n",
    "        edgecolor='darkblue',\n",
    "        linewidth=0.5,\n",
    "        label='Unassigned Buildings'\n",
    "    )\n",
    "\n",
    "    # Add basemap\n",
    "    try:\n",
    "        cx.add_basemap(ax, source=basemap_provider, zoom='auto')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not add basemap: {e}. Plotting without it.\")\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', fontsize=12, framealpha=0.9)\n",
    "    \n",
    "    # Add title and statistics\n",
    "    stats_text = f\"Census Blocks: {len(census_blocks_gdf)}\\nUnassigned Buildings: {len(buildings_gdf)}\"\n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_buildings_with_floor_area(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    floor_area_column: str = 'floor_area',\n",
    "    title: str = \"Building Footprints with Floor Area\",\n",
    "    figsize: tuple = (15, 15),\n",
    "    polygon_color: str = 'blue',\n",
    "    alpha: float = 0.5,\n",
    "    basemap_provider: cx.providers = cx.providers.OpenStreetMap.Mapnik,\n",
    "    label_fontsize: int = 8,\n",
    "    label_color: str = 'black',\n",
    "    label_background_alpha: float = 0.7,\n",
    "    label_bbox_pad: float = 0.2\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots building polygons from a GeoDataFrame on a contextily basemap,\n",
    "    labeling each building with its floor area.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Input GeoDataFrame with building geometries and a floor area column.\n",
    "        Must have a valid CRS.\n",
    "    floor_area_column : str, optional\n",
    "        The name of the column in gdf containing the floor area values.\n",
    "        Defaults to 'floor_area'.\n",
    "    title : str, optional\n",
    "        Plot title. Defaults to \"Building Footprints with Floor Area\".\n",
    "    figsize : tuple, optional\n",
    "        Figure size as (width, height). Defaults to (15, 15).\n",
    "    polygon_color : str, optional\n",
    "        Color for polygon geometries. Defaults to 'blue'.\n",
    "    alpha : float, optional\n",
    "        Transparency level for polygons (0-1). Defaults to 0.5.\n",
    "    basemap_provider : contextily.providers object, optional\n",
    "        The contextily basemap provider.\n",
    "        Defaults to cx.providers.OpenStreetMap.Mapnik.\n",
    "    label_fontsize : int, optional\n",
    "        Font size for the floor area labels. Defaults to 8.\n",
    "    label_color : str, optional\n",
    "        Color for the floor area labels. Defaults to 'black'.\n",
    "    label_background_alpha : float, optional\n",
    "        Alpha for the label background box (0-1). Defaults to 0.7.\n",
    "    label_bbox_pad : float, optional\n",
    "        Padding for the label background box. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Displays the plot.\n",
    "    \"\"\"\n",
    "    if not isinstance(gdf, gpd.GeoDataFrame):\n",
    "        print(\"Input must be a GeoDataFrame.\")\n",
    "        return\n",
    "    if gdf.empty:\n",
    "        print(\"GeoDataFrame is empty. Nothing to plot.\")\n",
    "        return\n",
    "    \n",
    "    if floor_area_column not in gdf.columns:\n",
    "        print(f\"Column '{floor_area_column}' not found in GeoDataFrame.\")\n",
    "        return\n",
    "    if gdf.crs is None:\n",
    "        print(\"GeoDataFrame must have a Coordinate Reference System (CRS) defined.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the GeoDataFrame is in Web Mercator projection for contextily\n",
    "    gdf_web_mercator = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot polygons\n",
    "    gdf_web_mercator.plot(\n",
    "        ax=ax,\n",
    "        color=polygon_color,\n",
    "        alpha=alpha,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "\n",
    "    # Add basemap\n",
    "    try:\n",
    "        cx.add_basemap(ax, source=basemap_provider, zoom='auto')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not add basemap: {e}. Plotting without it.\")\n",
    "\n",
    "\n",
    "    # Add floor area labels\n",
    "    for idx, row in gdf_web_mercator.iterrows():\n",
    "        try:\n",
    "            # Use a representative point for labeling, robust to invalid polygons\n",
    "            point_for_label = row.geometry.representative_point()\n",
    "            if point_for_label.is_empty: # Check if representative_point is valid\n",
    "                 # Fallback to centroid if representative_point is empty (should be rare)\n",
    "                point_for_label = row.geometry.centroid\n",
    "            \n",
    "            if not point_for_label.is_empty: # Final check before plotting text\n",
    "                floor_area = row[floor_area_column]\n",
    "                label = f\"{floor_area:,.0f} m²\" if pd.notnull(floor_area) else \"N/A\"\n",
    "                \n",
    "                ax.text(\n",
    "                    point_for_label.x,\n",
    "                    point_for_label.y,\n",
    "                    label,\n",
    "                    fontsize=label_fontsize,\n",
    "                    color=label_color,\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    bbox=dict(\n",
    "                        boxstyle='round,pad=' + str(label_bbox_pad),\n",
    "                        fc='white',\n",
    "                        alpha=label_background_alpha,\n",
    "                        ec='none' # No edge color for bbox\n",
    "                    )\n",
    "                )\n",
    "        except GEOSException:\n",
    "            print(f\"Warning: Could not generate a representative point for geometry at index {idx}. Skipping label.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while labeling geometry at index {idx}: {e}\")\n",
    "\n",
    "\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the unassigned buildings with census blocks\n",
    "print(f\"Plotting {len(unassigned_buildings)} unassigned buildings with {len(census_blocks)} census blocks\")\n",
    "plot_unassigned_buildings_with_census_blocks(unassigned_buildings, census_blocks)\n",
    "\n",
    "# Randomly sample ten buildings from the unassigned buildings for detailed view\n",
    "if len(unassigned_buildings) > 10:\n",
    "    samples = unassigned_buildings.sample(n=10, random_state=1)\n",
    "    plot_buildings_with_floor_area(samples, title=\"Sample of Unassigned Buildings with Floor Area\")\n",
    "else:\n",
    "    plot_buildings_with_floor_area(unassigned_buildings, title=\"All Unassigned Buildings with Floor Area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "def plot_buildings(\n",
    "    geojson_path: str,\n",
    "    title: str = \"Building Footprints\",\n",
    "    figsize: tuple = (12, 12),\n",
    "    polygon_color: str = 'blue',\n",
    "    alpha: float = 0.6,\n",
    "    basemap_provider=ctx.providers.OpenStreetMap.Mapnik\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads a GeoJSON file and plots building footprints on a web map using Contextily.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    geojson_path : str\n",
    "        Path to the GeoJSON file containing building polygons.\n",
    "    title : str, optional\n",
    "        Plot title. Defaults to \"Building Footprints\".\n",
    "    figsize : tuple, optional\n",
    "        Figure size as (width, height). Defaults to (12, 12).\n",
    "    polygon_color : str, optional\n",
    "        Color for building polygons. Defaults to 'blue'.\n",
    "    alpha : float, optional\n",
    "        Polygon transparency. Defaults to 0.6.\n",
    "    basemap_provider : contextily provider, optional\n",
    "        Tile provider. Defaults to OpenStreetMap.Mapnik.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Load data\n",
    "    try:\n",
    "        gdf = gpd.read_file(geojson_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading GeoJSON: {e}\")\n",
    "        return\n",
    "\n",
    "    # # Step 2: Ensure valid CRS\n",
    "    # if gdf.crs is None or gdf.crs.to_string().lower() in [\"urn:ogc:def:crs:ogc:1.3:crs84\", \"crs84\"]:\n",
    "    #     gdf = gdf.set_crs(epsg=4326)  # WGS84 lon/lat\n",
    "\n",
    "    # Step 3: Reproject to Web Mercator\n",
    "    gdf_web_mercator = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    # Step 4: Plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    gdf_web_mercator.plot(\n",
    "        ax=ax,\n",
    "        color=polygon_color,\n",
    "        alpha=alpha,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        ctx.add_basemap(ax, source=basemap_provider, crs=gdf_web_mercator.crs)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not add basemap: {e}. Plotting without basemap.\")\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "path = \"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/MA/Middlesex_County/Cambridge_city/MICROSOFT_BUILDINGS/microsoft_buildings_25_017_11000.geojson\"\n",
    "\n",
    "plot_buildings(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "gdf = gpd.read_file(path)\n",
    "centroid = gdf.unary_union.centroid\n",
    "m = folium.Map(location=[centroid.y, centroid.x], zoom_start=12)\n",
    "folium.GeoJson(gdf).add_to(m)\n",
    "m.save(\"debug_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "path_ms = \"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/buildings_with_ms_height.geojson\"\n",
    "gdf = gpd.read_file(path_ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from shapely.errors import GEOSException\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_buildings_by_height_with_stats_separate(\n",
    "    gdf: gpd.GeoDataFrame,\n",
    "    height_column: str = 'height',\n",
    "    floor_area_column: str = 'floor_area',\n",
    "    title: str = \"Buildings Colored by Height\",\n",
    "    figsize: tuple = (15, 15),\n",
    "    alpha: float = 0.7,\n",
    "    basemap_provider=ctx.providers.OpenStreetMap.Mapnik,\n",
    "    label_fontsize: int = 6,\n",
    "    label_color: str = 'black',\n",
    "    label_background_alpha: float = 0.8,\n",
    "    n_bins: int = 5,\n",
    "    colormap: str = 'viridis',\n",
    "    show_labels: bool = True,\n",
    "    sample_for_labels: int = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Plots building polygons colored by height with floor area labels and provides statistical analysis.\n",
    "    Creates two separate plots for better readability.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gdf : GeoDataFrame\n",
    "        Input GeoDataFrame with building geometries, height, and floor area columns\n",
    "    height_column : str\n",
    "        Column name containing height values (will be converted to numeric)\n",
    "    floor_area_column : str \n",
    "        Column name containing floor area values for labels\n",
    "    title : str\n",
    "        Plot title\n",
    "    figsize : tuple\n",
    "        Figure size as (width, height)\n",
    "    alpha : float\n",
    "        Transparency level for polygons (0-1)\n",
    "    basemap_provider : contextily provider\n",
    "        Basemap tile provider\n",
    "    label_fontsize : int\n",
    "        Font size for floor area labels\n",
    "    label_color : str\n",
    "        Color for floor area labels\n",
    "    label_background_alpha : float\n",
    "        Alpha for label background boxes\n",
    "    n_bins : int\n",
    "        Number of bins for height categorization\n",
    "    colormap : str\n",
    "        Matplotlib colormap name for height coloring\n",
    "    show_labels : bool\n",
    "        Whether to show floor area labels\n",
    "    sample_for_labels : int or None\n",
    "        If provided, randomly sample this many buildings for labeling (to avoid clutter)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Statistical analysis results\n",
    "    \"\"\"\n",
    "    \n",
    "    if gdf.empty:\n",
    "        print(\"GeoDataFrame is empty. Nothing to plot.\")\n",
    "        return {}\n",
    "    \n",
    "    # Create working copy\n",
    "    buildings = gdf.copy()\n",
    "    \n",
    "    # Convert height to numeric, handling string values and invalid data\n",
    "    def parse_height(height_val):\n",
    "        \"\"\"Parse height value from various formats\"\"\"\n",
    "        if pd.isna(height_val) or height_val is None:\n",
    "            return np.nan\n",
    "        try:\n",
    "            # Handle string values that might have units\n",
    "            height_str = str(height_val).strip()\n",
    "            # Remove common units\n",
    "            height_str = height_str.replace('m', '').replace('meters', '').replace('ft', '').replace('feet', '').strip()\n",
    "            height_float = float(height_str)\n",
    "            # Sanity check: reasonable building height\n",
    "            if 0.5 <= height_float <= 500.0:\n",
    "                return height_float\n",
    "            else:\n",
    "                return np.nan\n",
    "        except (ValueError, TypeError):\n",
    "            return np.nan\n",
    "    \n",
    "    # Parse height values\n",
    "    buildings[height_column] = buildings[height_column].apply(parse_height)\n",
    "    \n",
    "    # Statistical Analysis\n",
    "    print(\"=\"*60)\n",
    "    print(\"BUILDING HEIGHT STATISTICAL ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Basic statistics\n",
    "    total_buildings = len(buildings)\n",
    "    buildings_with_height = buildings[height_column].notna().sum()\n",
    "    height_coverage = (buildings_with_height / total_buildings) * 100\n",
    "    \n",
    "    print(f\"Total buildings: {total_buildings:,}\")\n",
    "    print(f\"Buildings with height data: {buildings_with_height:,}\")\n",
    "    print(f\"Height data coverage: {height_coverage:.1f}%\")\n",
    "    print(f\"Buildings with missing height: {total_buildings - buildings_with_height:,} ({100-height_coverage:.1f}%)\")\n",
    "    \n",
    "    # Height statistics for valid values\n",
    "    height_data = buildings[height_column].dropna()\n",
    "    if len(height_data) > 0:\n",
    "        print(f\"\\nHeight Statistics (meters):\")\n",
    "        print(f\"  Mean: {height_data.mean():.2f}m\")\n",
    "        print(f\"  Median: {height_data.median():.2f}m\")\n",
    "        print(f\"  Std Dev: {height_data.std():.2f}m\")\n",
    "        print(f\"  Min: {height_data.min():.2f}m\")\n",
    "        print(f\"  Max: {height_data.max():.2f}m\")\n",
    "        print(f\"  25th percentile: {height_data.quantile(0.25):.2f}m\")\n",
    "        print(f\"  75th percentile: {height_data.quantile(0.75):.2f}m\")\n",
    "        \n",
    "        # Outlier analysis using IQR method\n",
    "        Q1 = height_data.quantile(0.25)\n",
    "        Q3 = height_data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = height_data[(height_data < lower_bound) | (height_data > upper_bound)]\n",
    "        \n",
    "        print(f\"\\nOutlier Analysis (IQR method):\")\n",
    "        print(f\"  IQR: {IQR:.2f}m\")\n",
    "        print(f\"  Lower bound: {lower_bound:.2f}m\")\n",
    "        print(f\"  Upper bound: {upper_bound:.2f}m\")\n",
    "        print(f\"  Number of outliers: {len(outliers)} ({len(outliers)/len(height_data)*100:.1f}%)\")\n",
    "        if len(outliers) > 0:\n",
    "            print(f\"  Outlier range: {outliers.min():.2f}m - {outliers.max():.2f}m\")\n",
    "        \n",
    "        # Height distribution by bins\n",
    "        print(f\"\\nHeight Distribution:\")\n",
    "        bins = np.linspace(height_data.min(), height_data.max(), n_bins + 1)\n",
    "        height_counts, _ = np.histogram(height_data, bins=bins)\n",
    "        for i in range(len(bins)-1):\n",
    "            count = height_counts[i]\n",
    "            percentage = (count / len(height_data)) * 100\n",
    "            print(f\"  {bins[i]:.1f}m - {bins[i+1]:.1f}m: {count} buildings ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Floor area statistics for context\n",
    "    if floor_area_column in buildings.columns:\n",
    "        area_data = buildings[floor_area_column].dropna()\n",
    "        if len(area_data) > 0:\n",
    "            print(f\"\\nFloor Area Statistics (m²):\")\n",
    "            print(f\"  Mean: {area_data.mean():.0f}m²\")\n",
    "            print(f\"  Median: {area_data.median():.0f}m²\")\n",
    "            print(f\"  Min: {area_data.min():.0f}m²\")\n",
    "            print(f\"  Max: {area_data.max():.0f}m²\")\n",
    "    \n",
    "    # Now create the plots\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"CREATING VISUALIZATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filter buildings with valid height data for plotting\n",
    "    buildings_with_valid_height = buildings[buildings[height_column].notna()].copy()\n",
    "    buildings_without_height = buildings[buildings[height_column].isna()].copy()\n",
    "    \n",
    "    if len(buildings_with_valid_height) == 0:\n",
    "        print(\"No buildings with valid height data to plot.\")\n",
    "        return {\"error\": \"No valid height data\"}\n",
    "    \n",
    "    # Project to Web Mercator for plotting\n",
    "    if buildings.crs != \"EPSG:3857\":\n",
    "        buildings_web_mercator = buildings.to_crs(\"EPSG:3857\")\n",
    "        buildings_with_valid_height_web_mercator = buildings_with_valid_height.to_crs(\"EPSG:3857\")\n",
    "        if len(buildings_without_height) > 0:\n",
    "            buildings_without_height_web_mercator = buildings_without_height.to_crs(\"EPSG:3857\")\n",
    "    else:\n",
    "        buildings_web_mercator = buildings.copy()\n",
    "        buildings_with_valid_height_web_mercator = buildings_with_valid_height.copy()\n",
    "        buildings_without_height_web_mercator = buildings_without_height.copy()\n",
    "    \n",
    "    # Create height bins for coloring\n",
    "    height_values = buildings_with_valid_height_web_mercator[height_column]\n",
    "    min_height = height_values.min()\n",
    "    max_height = height_values.max()\n",
    "    \n",
    "    # Create bins\n",
    "    bins = np.linspace(min_height, max_height, n_bins + 1)\n",
    "    buildings_with_valid_height_web_mercator['height_bin'] = pd.cut(\n",
    "        buildings_with_valid_height_web_mercator[height_column], \n",
    "        bins=bins, \n",
    "        labels=[f\"{bins[i]:.1f}-{bins[i+1]:.1f}m\" for i in range(len(bins)-1)],\n",
    "        include_lowest=True\n",
    "    )\n",
    "    \n",
    "    # PLOT 1: Main map visualization\n",
    "    print(\"Creating main map plot...\")\n",
    "    fig1, ax1 = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    # Plot buildings without height in gray\n",
    "    if len(buildings_without_height) > 0:\n",
    "        buildings_without_height_web_mercator.plot(\n",
    "            ax=ax1,\n",
    "            color='lightgray',\n",
    "            alpha=alpha*0.5,\n",
    "            edgecolor='gray',\n",
    "            linewidth=0.3,\n",
    "            label=f'No height data ({len(buildings_without_height)})'\n",
    "        )\n",
    "    \n",
    "    # Plot buildings with height using colormap\n",
    "    buildings_with_valid_height_web_mercator.plot(\n",
    "        ax=ax1,\n",
    "        column=height_column,\n",
    "        cmap=colormap,\n",
    "        alpha=alpha,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.3,\n",
    "        legend=True,\n",
    "        legend_kwds={'label': 'Height (m)', 'shrink': 0.8}\n",
    "    )\n",
    "    \n",
    "    # Add basemap\n",
    "    try:\n",
    "        ctx.add_basemap(ax1, source=basemap_provider, crs=buildings_web_mercator.crs)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not add basemap: {e}\")\n",
    "    \n",
    "    # Add floor area labels if requested\n",
    "    if show_labels and floor_area_column in buildings.columns:\n",
    "        # Sample buildings for labeling if requested\n",
    "        if sample_for_labels and len(buildings_with_valid_height_web_mercator) > sample_for_labels:\n",
    "            buildings_to_label = buildings_with_valid_height_web_mercator.sample(n=sample_for_labels, random_state=42)\n",
    "        else:\n",
    "            buildings_to_label = buildings_with_valid_height_web_mercator\n",
    "        \n",
    "        print(f\"Adding floor area labels to {len(buildings_to_label)} buildings...\")\n",
    "        \n",
    "        for idx, row in buildings_to_label.iterrows():\n",
    "            try:\n",
    "                point_for_label = row.geometry.representative_point()\n",
    "                if not point_for_label.is_empty:\n",
    "                    floor_area = row[floor_area_column]\n",
    "                    if pd.notnull(floor_area):\n",
    "                        label = f\"{floor_area:,.0f}m²\"\n",
    "                        ax1.text(\n",
    "                            point_for_label.x,\n",
    "                            point_for_label.y,\n",
    "                            label,\n",
    "                            fontsize=label_fontsize,\n",
    "                            color=label_color,\n",
    "                            ha='center',\n",
    "                            va='center',\n",
    "                            bbox=dict(\n",
    "                                boxstyle='round,pad=0.2',\n",
    "                                fc='white',\n",
    "                                alpha=label_background_alpha,\n",
    "                                ec='none'\n",
    "                            )\n",
    "                        )\n",
    "            except GEOSException:\n",
    "                continue\n",
    "    \n",
    "    ax1.set_title(f\"{title}\\n{buildings_with_height:,} buildings with height data\", fontsize=16, pad=20)\n",
    "    ax1.set_axis_off()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # PLOT 2: Statistical analysis dashboard\n",
    "    print(\"Creating statistical analysis plots...\")\n",
    "    fig2, axes2 = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Distribution histogram\n",
    "    if len(height_data) > 0:\n",
    "        axes2[0,0].hist(height_data, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes2[0,0].axvline(height_data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {height_data.mean():.1f}m')\n",
    "        axes2[0,0].axvline(height_data.median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {height_data.median():.1f}m')\n",
    "        axes2[0,0].set_xlabel('Height (meters)', fontsize=12)\n",
    "        axes2[0,0].set_ylabel('Number of Buildings', fontsize=12)\n",
    "        axes2[0,0].set_title('Height Distribution', fontsize=14, fontweight='bold')\n",
    "        axes2[0,0].legend()\n",
    "        axes2[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    if len(height_data) > 0:\n",
    "        bp = axes2[0,1].boxplot(height_data, patch_artist=True)\n",
    "        bp['boxes'][0].set_facecolor('lightblue')\n",
    "        axes2[0,1].set_title('Height Distribution (Box Plot)', fontsize=14, fontweight='bold')\n",
    "        axes2[0,1].set_ylabel('Height (m)', fontsize=12)\n",
    "        axes2[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add outlier information\n",
    "        if len(outliers) > 0:\n",
    "            axes2[0,1].text(0.02, 0.98, f'Outliers: {len(outliers)} ({len(outliers)/len(height_data)*100:.1f}%)', \n",
    "                           transform=axes2[0,1].transAxes, verticalalignment='top',\n",
    "                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Coverage pie chart\n",
    "    coverage_data = [buildings_with_height, total_buildings - buildings_with_height]\n",
    "    coverage_labels = [f'With Height\\n({buildings_with_height:,})', f'Missing Height\\n({total_buildings - buildings_with_height:,})']\n",
    "    colors = ['#66b3ff', '#ffcc99']\n",
    "    axes2[1,0].pie(coverage_data, labels=coverage_labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "    axes2[1,0].set_title('Height Data Coverage', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Height bins bar chart\n",
    "    if len(height_data) > 0:\n",
    "        bin_counts = buildings_with_valid_height['height_bin'].value_counts().sort_index()\n",
    "        bars = axes2[1,1].bar(range(len(bin_counts)), bin_counts.values, color='lightcoral', edgecolor='black')\n",
    "        axes2[1,1].set_xticks(range(len(bin_counts)))\n",
    "        axes2[1,1].set_xticklabels(bin_counts.index, rotation=45, ha='right')\n",
    "        axes2[1,1].set_xlabel('Height Bins', fontsize=12)\n",
    "        axes2[1,1].set_ylabel('Number of Buildings', fontsize=12)\n",
    "        axes2[1,1].set_title('Buildings by Height Range', fontsize=14, fontweight='bold')\n",
    "        axes2[1,1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, count in zip(bars, bin_counts.values):\n",
    "            height = bar.get_height()\n",
    "            axes2[1,1].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                           f'{count}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.suptitle('Building Height Statistical Analysis', fontsize=16, fontweight='bold', y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "    \n",
    "    # PLOT 3: Height vs Floor Area scatter plot (if floor area data is available)\n",
    "    if floor_area_column in buildings.columns:\n",
    "        valid_both = buildings[(buildings[height_column].notna()) & (buildings[floor_area_column].notna())]\n",
    "        if len(valid_both) > 0:\n",
    "            print(\"Creating height vs floor area correlation plot...\")\n",
    "            fig3, ax3 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "            \n",
    "            scatter = ax3.scatter(valid_both[floor_area_column], valid_both[height_column], \n",
    "                                alpha=0.6, c=valid_both[height_column], cmap=colormap, s=30)\n",
    "            ax3.set_xlabel('Floor Area (m²)', fontsize=12)\n",
    "            ax3.set_ylabel('Height (m)', fontsize=12)\n",
    "            ax3.set_title('Building Height vs Floor Area Correlation', fontsize=14, fontweight='bold')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add colorbar\n",
    "            cbar = plt.colorbar(scatter, ax=ax3)\n",
    "            cbar.set_label('Height (m)', fontsize=12)\n",
    "            \n",
    "            # Calculate and display correlation\n",
    "            correlation = valid_both[height_column].corr(valid_both[floor_area_column])\n",
    "            ax3.text(0.02, 0.98, f'Correlation: {correlation:.3f}', \n",
    "                    transform=ax3.transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                    fontsize=12)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # Return statistical summary\n",
    "    stats_summary = {\n",
    "        'total_buildings': total_buildings,\n",
    "        'buildings_with_height': buildings_with_height,\n",
    "        'height_coverage_percent': height_coverage,\n",
    "        'height_stats': {\n",
    "            'mean': height_data.mean() if len(height_data) > 0 else None,\n",
    "            'median': height_data.median() if len(height_data) > 0 else None,\n",
    "            'std': height_data.std() if len(height_data) > 0 else None,\n",
    "            'min': height_data.min() if len(height_data) > 0 else None,\n",
    "            'max': height_data.max() if len(height_data) > 0 else None,\n",
    "            'q25': height_data.quantile(0.25) if len(height_data) > 0 else None,\n",
    "            'q75': height_data.quantile(0.75) if len(height_data) > 0 else None\n",
    "        },\n",
    "        'outliers': {\n",
    "            'count': len(outliers) if len(height_data) > 0 else 0,\n",
    "            'percentage': len(outliers)/len(height_data)*100 if len(height_data) > 0 else 0,\n",
    "            'lower_bound': lower_bound if len(height_data) > 0 else None,\n",
    "            'upper_bound': upper_bound if len(height_data) > 0 else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return stats_summary\n",
    "\n",
    "# Example usage with the separate plots version:\n",
    "path = \"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/buildings_with_ms_height.geojson\"\n",
    "buildings_gdf = gpd.read_file(path)\n",
    "\n",
    "stats = plot_buildings_by_height_with_stats_separate(\n",
    "    gdf=buildings_gdf,\n",
    "    height_column='height',\n",
    "    floor_area_column='floor_area',\n",
    "    show_labels=True,\n",
    "    sample_for_labels=50,  # Only label 50 random buildings to avoid clutter\n",
    "    n_bins=6,\n",
    "    colormap='plasma',\n",
    "    figsize=(14, 14)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now checking the buildings where height is equal to null : \n",
    "osm_path = \"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/buildings_with_ms_height.geojson\"\n",
    "ms_buildings_path = \"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/MA/Middlesex_County/Cambridge_city/MICROSOFT_BUILDINGS/ms_buildings_output.geojson\"\n",
    "\n",
    "osm_gdf = gpd.read_file(osm_path)\n",
    "ms_gdf = gpd.read_file(ms_buildings_path)\n",
    "\n",
    "\n",
    "# Filter buildings with null height\n",
    "null_height_buildings = osm_gdf[osm_gdf['height'].isna()]\n",
    "\n",
    "# Print statistics about null height buildings\n",
    "print(f\"Total buildings: {len(null_height_buildings)}\")\n",
    "\n",
    "# Plot the null height buildings\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "null_height_buildings.plot(ax=ax, color='red', markersize=10)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define the input and output paths\n",
    "input_file = Path(\"/Users/magic-rabbit/Documents/MA-data/NREL_Residential_typology.tsv\")\n",
    "output_dir = Path(\"county_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Process the file in chunks\n",
    "chunk_size = 100000\n",
    "processed_counties = set()\n",
    "\n",
    "logger.info(\"Starting to process the TSV file...\")\n",
    "\n",
    "for chunk in pd.read_csv(input_file, sep=\"\\t\", chunksize=chunk_size):\n",
    "    # Convert county to string for consistent naming\n",
    "    chunk['in.county'] = chunk['in.county'].astype(str)\n",
    "    logger.info(chunk)\n",
    "    \n",
    "    # Process each county in the current chunk\n",
    "    for county_id, group in chunk.groupby('in.county'):\n",
    "        if county_id not in processed_counties:\n",
    "            output_file = output_dir / f\"county_{county_id}.parquet\"\n",
    "            group.to_parquet(output_file, index=False)\n",
    "            processed_counties.add(county_id)\n",
    "            logger.info(f\"Saved data for county {county_id}\")\n",
    "    \n",
    "    # Optional: Add a progress indicator\n",
    "    logger.info(f\"Processed {len(processed_counties)} unique counties so far\")\n",
    "\n",
    "logger.info(\"Finished processing all counties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load a single county's data\n",
    "import pandas as pd\n",
    "\n",
    "# Load one county file (using G0100370 as an example)\n",
    "county_data = pd.read_parquet(\"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/notebooks/county_data/county_G0100810.parquet\")\n",
    "\n",
    "# Display basic information about the data\n",
    "print(\"Data shape:\", county_data.shape)\n",
    "print(\"\\nColumns:\", county_data.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(county_data.head())\n",
    "\n",
    "\n",
    "columns_to_show = [\n",
    "    'in.county',\n",
    "    'in.state',\n",
    "    'in.puma',\n",
    "    'in.ahs_region',\n",
    "    'in.american_housing_survey_region',\n",
    "    'in.resstock_county_id',\n",
    "    'in.resstock_puma_id',\n",
    "    'in.nhgis_county_gisjoin',\n",
    "    'in.nhgis_puma_gisjoin',\n",
    "    'in.state_name'\n",
    "]\n",
    "\n",
    "# Display the first 5 random rows of the selected columns\n",
    "print(county_data[columns_to_show].sample(n=3, random_state=1))\n",
    "\n",
    "# Show some basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "display(county_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point, Polygon\n",
    "import numpy as np\n",
    "\n",
    "def plot_height_data_gaps_limited(osm_buildings_path, ms_buildings_path, max_overlaps=100, output_path=None):\n",
    "    \"\"\"\n",
    "    Plot first N OSM buildings with missing height data alongside overlapping MS buildings.\n",
    "    Shows MS building centroids as red X markers.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    osm_buildings_path : str\n",
    "        Path to OSM buildings with height data\n",
    "    ms_buildings_path : str  \n",
    "        Path to MS buildings data\n",
    "    max_overlaps : int\n",
    "        Maximum number of overlaps to plot (default 100)\n",
    "    output_path : str, optional\n",
    "        Path to save the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading building data...\")\n",
    "    osm_gdf = gpd.read_file(osm_buildings_path)\n",
    "    ms_gdf = gpd.read_file(ms_buildings_path)\n",
    "    \n",
    "    # Filter OSM buildings with null height\n",
    "    null_height_osm = osm_gdf[osm_gdf['height'].isna()].copy()\n",
    "    print(f\"OSM buildings without height data: {len(null_height_osm)}\")\n",
    "    print(f\"Total MS buildings: {len(ms_gdf)}\")\n",
    "    \n",
    "    if len(null_height_osm) == 0:\n",
    "        print(\"No OSM buildings without height data found!\")\n",
    "        return\n",
    "    \n",
    "    # Ensure same CRS for spatial operations\n",
    "    if null_height_osm.crs != ms_gdf.crs:\n",
    "        print(\"Aligning CRS for spatial operations...\")\n",
    "        ms_gdf = ms_gdf.to_crs(null_height_osm.crs)\n",
    "    \n",
    "    # Find MS buildings that intersect with null height OSM buildings (limited)\n",
    "    print(f\"Finding first {max_overlaps} intersecting MS buildings...\")\n",
    "    intersecting_pairs = []\n",
    "    \n",
    "    # Create spatial index for efficiency\n",
    "    ms_sindex = ms_gdf.sindex\n",
    "    \n",
    "    for idx, osm_building in null_height_osm.iterrows():\n",
    "        if len(intersecting_pairs) >= max_overlaps:\n",
    "            break\n",
    "            \n",
    "        # Get potential matches from spatial index\n",
    "        possible_matches_idx = list(ms_sindex.intersection(osm_building.geometry.bounds))\n",
    "        possible_matches = ms_gdf.iloc[possible_matches_idx]\n",
    "        \n",
    "        # Check actual intersections\n",
    "        intersecting_ms = possible_matches[possible_matches.intersects(osm_building.geometry)]\n",
    "        \n",
    "        for ms_idx, ms_building in intersecting_ms.iterrows():\n",
    "            if len(intersecting_pairs) >= max_overlaps:\n",
    "                break\n",
    "                \n",
    "            intersecting_pairs.append({\n",
    "                'osm_idx': idx,\n",
    "                'ms_idx': ms_idx,\n",
    "                'osm_geometry': osm_building.geometry,\n",
    "                'ms_geometry': ms_building.geometry,\n",
    "                'ms_centroid': ms_building.geometry.centroid,\n",
    "                'ms_height': ms_building.get('height', 'Unknown'),\n",
    "                'ms_confidence': ms_building.get('confidence', 'Unknown'),\n",
    "                'centroid_within': osm_building.geometry.contains(ms_building.geometry.centroid)\n",
    "            })\n",
    "    \n",
    "    print(f\"Found {len(intersecting_pairs)} OSM-MS building intersection pairs (limited to {max_overlaps})\")\n",
    "    \n",
    "    if len(intersecting_pairs) == 0:\n",
    "        print(\"No intersections found between null height OSM buildings and MS buildings\")\n",
    "        return\n",
    "    \n",
    "    # Get unique OSM buildings from the pairs for plotting\n",
    "    unique_osm_indices = list(set(p['osm_idx'] for p in intersecting_pairs))\n",
    "    selected_osm_buildings = null_height_osm.loc[unique_osm_indices]\n",
    "    \n",
    "    # Convert to Web Mercator for contextily basemap\n",
    "    selected_osm_web = selected_osm_buildings.to_crs(epsg=3857)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "    \n",
    "    # Plot selected OSM buildings without height (light gray background)\n",
    "    selected_osm_web.plot(ax=ax, color='lightgray', alpha=0.6, \n",
    "                         edgecolor='gray', linewidth=0.5)\n",
    "    \n",
    "    # Separate geometries by centroid position\n",
    "    centroids_within = []\n",
    "    centroids_outside = []\n",
    "    osm_geoms_within = []\n",
    "    osm_geoms_outside = []\n",
    "    ms_geoms_within = []\n",
    "    ms_geoms_outside = []\n",
    "    \n",
    "    for pair in intersecting_pairs:\n",
    "        # Convert geometries to Web Mercator\n",
    "        osm_geom_web = gpd.GeoSeries([pair['osm_geometry']], crs=null_height_osm.crs).to_crs(epsg=3857)\n",
    "        ms_geom_web = gpd.GeoSeries([pair['ms_geometry']], crs=ms_gdf.crs).to_crs(epsg=3857)\n",
    "        ms_centroid_web = gpd.GeoSeries([pair['ms_centroid']], crs=ms_gdf.crs).to_crs(epsg=3857)\n",
    "        \n",
    "        if pair['centroid_within']:\n",
    "            # Centroid is within OSM building\n",
    "            osm_geoms_within.extend(osm_geom_web.geometry)\n",
    "            ms_geoms_within.extend(ms_geom_web.geometry)\n",
    "            centroids_within.extend(ms_centroid_web.geometry)\n",
    "        else:\n",
    "            # Centroid is outside OSM building\n",
    "            osm_geoms_outside.extend(osm_geom_web.geometry)\n",
    "            ms_geoms_outside.extend(ms_geom_web.geometry)\n",
    "            centroids_outside.extend(ms_centroid_web.geometry)\n",
    "    \n",
    "    # Plot OSM buildings - green if centroid within, red if outside\n",
    "    if osm_geoms_within:\n",
    "        gpd.GeoSeries(osm_geoms_within, crs='EPSG:3857').plot(\n",
    "            ax=ax, color='green', alpha=0.7, edgecolor='darkgreen', linewidth=2)\n",
    "    \n",
    "    if osm_geoms_outside:\n",
    "        gpd.GeoSeries(osm_geoms_outside, crs='EPSG:3857').plot(\n",
    "            ax=ax, color='red', alpha=0.7, edgecolor='darkred', linewidth=2)\n",
    "    \n",
    "    # Plot MS buildings - blue if centroid within, orange if outside\n",
    "    if ms_geoms_within:\n",
    "        gpd.GeoSeries(ms_geoms_within, crs='EPSG:3857').plot(\n",
    "            ax=ax, color='blue', alpha=0.5, edgecolor='darkblue', linewidth=1)\n",
    "    \n",
    "    if ms_geoms_outside:\n",
    "        gpd.GeoSeries(ms_geoms_outside, crs='EPSG:3857').plot(\n",
    "            ax=ax, color='orange', alpha=0.5, edgecolor='darkorange', linewidth=1)\n",
    "    \n",
    "    # Plot all MS building centroids as red X markers\n",
    "    all_centroids = centroids_within + centroids_outside\n",
    "    if all_centroids:\n",
    "        gpd.GeoSeries(all_centroids, crs='EPSG:3857').plot(\n",
    "            ax=ax, color='red', marker='x', markersize=5, alpha=1.0)\n",
    "    \n",
    "    # Add basemap\n",
    "    try:\n",
    "        ctx.add_basemap(ax, crs='EPSG:3857', source=ctx.providers.OpenStreetMap.Mapnik, alpha=0.7)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not add basemap: {e}\")\n",
    "    \n",
    "    # Create custom legend\n",
    "    from matplotlib.patches import Patch\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    legend_elements = [\n",
    "        Patch(facecolor='lightgray', alpha=0.6, label='OSM buildings without height'),\n",
    "        Patch(facecolor='green', alpha=0.7, label='OSM buildings (centroid within)'),\n",
    "        Patch(facecolor='red', alpha=0.7, label='OSM buildings (centroid outside)'),\n",
    "        Patch(facecolor='blue', alpha=0.5, label='MS buildings (centroid within)'),\n",
    "        Patch(facecolor='orange', alpha=0.5, label='MS buildings (centroid outside)'),\n",
    "        Line2D([0], [0], marker='x', color='red', linestyle='None', \n",
    "               markersize=10, label='MS building centroids')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(f'OSM Buildings Missing Height Data vs MS Buildings (First {len(intersecting_pairs)} overlaps)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Longitude', fontsize=12)\n",
    "    ax.set_ylabel('Latitude', fontsize=12)\n",
    "    \n",
    "    # Remove axis ticks for cleaner look\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY STATISTICS (First 100 overlaps)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    centroids_within_count = len(centroids_within)\n",
    "    centroids_outside_count = len(centroids_outside)\n",
    "    total = centroids_within_count + centroids_outside_count\n",
    "    \n",
    "    print(f\"Total intersections analyzed: {total}\")\n",
    "    print(f\"MS centroids WITHIN OSM buildings: {centroids_within_count} ({centroids_within_count/total*100:.1f}%)\")\n",
    "    print(f\"MS centroids OUTSIDE OSM buildings: {centroids_outside_count} ({centroids_outside_count/total*100:.1f}%)\")\n",
    "\n",
    "# Usage\n",
    "plot_height_data_gaps_limited(\n",
    "    osm_buildings_path=\"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/buildings_with_ms_height.geojson\",\n",
    "    ms_buildings_path=\"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/MA/Middlesex_County/Cambridge_city/MICROSOFT_BUILDINGS/ms_buildings_output.geojson\",\n",
    "    max_overlaps=100,\n",
    "    output_path=\"height_data_gap_analysis_100.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define the input and output paths\n",
    "input_file = Path(\"/Users/magic-rabbit/Documents/MA-data/NREL_Residential_typology.tsv\")\n",
    "output_dir = Path(\"county_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Process the file in chunks\n",
    "chunk_size = 100000\n",
    "processed_counties = set()\n",
    "\n",
    "logger.info(\"Starting to process the TSV file...\")\n",
    "\n",
    "for chunk in pd.read_csv(input_file, sep=\"\\t\", chunksize=chunk_size):\n",
    "    # Convert county to string for consistent naming\n",
    "    chunk['in.county'] = chunk['in.county'].astype(str)\n",
    "    logger.info(chunk)\n",
    "    \n",
    "    # Process each county in the current chunk\n",
    "    for county_id, group in chunk.groupby('in.county'):\n",
    "        if county_id not in processed_counties:\n",
    "            output_file = output_dir / f\"county_{county_id}.parquet\"\n",
    "            group.to_parquet(output_file, index=False)\n",
    "            processed_counties.add(county_id)\n",
    "            logger.info(f\"Saved data for county {county_id}\")\n",
    "    \n",
    "    # Optional: Add a progress indicator\n",
    "    logger.info(f\"Processed {len(processed_counties)} unique counties so far\")\n",
    "\n",
    "logger.info(\"Finished processing all counties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load a single county's data\n",
    "import pandas as pd\n",
    "\n",
    "# Load one county file (using G0100370 as an example)\n",
    "county_data = pd.read_parquet(\"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/notebooks/county_data/county_G0100810.parquet\")\n",
    "\n",
    "# Display basic information about the data\n",
    "print(\"Data shape:\", county_data.shape)\n",
    "print(\"\\nColumns:\", county_data.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(county_data.head())\n",
    "\n",
    "\n",
    "columns_to_show = [\n",
    "    'in.county',\n",
    "    'in.state',\n",
    "    'in.puma',\n",
    "    'in.ahs_region',\n",
    "    'in.american_housing_survey_region',\n",
    "    'in.resstock_county_id',\n",
    "    'in.resstock_puma_id',\n",
    "    'in.nhgis_county_gisjoin',\n",
    "    'in.nhgis_puma_gisjoin',\n",
    "    'in.state_name'\n",
    "]\n",
    "\n",
    "# Display the first 5 random rows of the selected columns\n",
    "print(county_data[columns_to_show].sample(n=3, random_state=1))\n",
    "\n",
    "# Show some basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "display(county_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_and_generate_res_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze a ResStock-style building dataset and return weighted distribution\n",
    "    of simplified residential building types.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame with building metadata including weights and building types.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    res_types_df : pd.DataFrame\n",
    "        A DataFrame summarizing building types and their weighted percentage shares.\n",
    "    \"\"\"\n",
    "\n",
    "    # === Exploratory Summary ===\n",
    "    print(\"=== Dataset Overview ===\")\n",
    "    print(df.info())\n",
    "    print(\"\\n=== Unique Building Types (ACS Classification) ===\")\n",
    "    print(df[\"in.geometry_building_type_acs\"].value_counts(dropna=False))\n",
    "    print(\"\\n=== Weight Column Summary ===\")\n",
    "    print(df[\"weight\"].describe())\n",
    "\n",
    "    # === Data Cleaning ===\n",
    "    df_clean = df.dropna(subset=[\"weight\", \"in.geometry_building_type_acs\"])\n",
    "\n",
    "    # === Mapping Raw Types to Simplified Codes ===\n",
    "    def map_building_type(bt: str) -> int:\n",
    "        if \"Detached\" in bt:\n",
    "            return 1  # SFH\n",
    "        elif \"Attached\" in bt:\n",
    "            return 2  # TH\n",
    "        elif \"2-4\" in bt:\n",
    "            return 3  # MFH\n",
    "        elif \"5+\" in bt:\n",
    "            return 4  # AB\n",
    "        else:\n",
    "            return None  # Unused/Other types\n",
    "\n",
    "    df_clean[\"Building_Type\"] = df_clean[\"in.geometry_building_type_acs\"].apply(map_building_type)\n",
    "    df_clean = df_clean.dropna(subset=[\"Building_Type\"])\n",
    "\n",
    "    # === Weighted Share Calculation ===\n",
    "    grouped = df_clean.groupby(\"Building_Type\")[\"weight\"].sum().reset_index()\n",
    "    total_weight = grouped[\"weight\"].sum()\n",
    "    grouped[\"Stati_res_percent\"] = grouped[\"weight\"] / total_weight * 100\n",
    "\n",
    "    return grouped[[\"Building_Type\", \"Stati_res_percent\"]]\n",
    "\n",
    "analyze_and_generate_res_types(county_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_and_generate_res_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze a ResStock-style building dataset and return weighted distribution\n",
    "    of simplified residential building types.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame with building metadata including weights and building types.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    res_types_df : pd.DataFrame\n",
    "        A DataFrame summarizing building types and their weighted percentage shares.\n",
    "    \"\"\"\n",
    "\n",
    "    # === Exploratory Summary ===\n",
    "    print(\"=== Dataset Overview ===\")\n",
    "    print(df.info())\n",
    "    print(\"\\n=== Unique Building Types (ACS Classification) ===\")\n",
    "    print(df[\"in.geometry_building_type_acs\"].value_counts(dropna=False))\n",
    "    print(\"\\n=== Weight Column Summary ===\")\n",
    "    print(df[\"weight\"].describe())\n",
    "\n",
    "    # === Data Cleaning ===\n",
    "    df_clean = df.dropna(subset=[\"weight\", \"in.geometry_building_type_acs\"])\n",
    "\n",
    "    # === Mapping Raw Types to Simplified Codes ===\n",
    "    def map_building_type(bt: str) -> int:\n",
    "        if \"Detached\" in bt:\n",
    "            return 1  # SFH\n",
    "        elif \"Attached\" in bt:\n",
    "            return 2  # TH\n",
    "        elif \"2-4\" in bt:\n",
    "            return 3  # MFH\n",
    "        elif \"5+\" in bt:\n",
    "            return 4  # AB\n",
    "        else:\n",
    "            return None  # Unused/Other types\n",
    "\n",
    "    df_clean[\"Building_Type\"] = df_clean[\"in.geometry_building_type_acs\"].apply(map_building_type)\n",
    "    df_clean = df_clean.dropna(subset=[\"Building_Type\"])\n",
    "\n",
    "    # === Weighted Share Calculation ===\n",
    "    grouped = df_clean.groupby(\"Building_Type\")[\"weight\"].sum().reset_index()\n",
    "    total_weight = grouped[\"weight\"].sum()\n",
    "    grouped[\"Stati_res_percent\"] = grouped[\"weight\"] / total_weight * 100\n",
    "\n",
    "    return grouped[[\"Building_Type\", \"Stati_res_percent\"]]\n",
    "\n",
    "analyze_and_generate_res_types(county_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to visualize buildings in a given census block\n",
    "import contextily as ctx\n",
    "\n",
    "# I want to now visualize the geometry of  all buildings in a for which census_block_id = 250173546012000 and also draw the cesnsu block boundary by filtereing GEOID20\n",
    "\n",
    "census_block_path = \"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/MA/Middlesex_County/Cambridge_city/CENSUS/target_region_blocks.geojson\"\n",
    "census_block_gdf = gpd.read_file(census_block_path)\n",
    "\n",
    "# Filter census block by GEOID20\n",
    "census_block_boundary = census_block_gdf[census_block_gdf['GEOID20'] == '250173547001005']\n",
    "\n",
    "# Load buildings with ids\n",
    "buildings_with_ids_path = \"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/06_residential_buildings_with_building_type.geojson\"\n",
    "buildings_with_ids_gdf = gpd.read_file(buildings_with_ids_path)\n",
    "print(f\"Number of buildings in the census block: {len(buildings_with_ids_gdf)}\")\n",
    "\n",
    "# Filter buildings by census block ID\n",
    "buildings_in_block = buildings_with_ids_gdf[buildings_with_ids_gdf['census_block_id'] == '250173547001005']\n",
    "\n",
    "# Convert to Web Mercator for contextily\n",
    "census_block_mercator = census_block_boundary.to_crs(epsg=3857)\n",
    "buildings_mercator = buildings_in_block.to_crs(epsg=3857)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Plot census block boundary in blue\n",
    "census_block_mercator.plot(ax=ax, color='blue', alpha=0.3, edgecolor='blue', linewidth=3)\n",
    "\n",
    "# Plot buildings in red\n",
    "buildings_mercator.plot(ax=ax, color='red', alpha=0.8)\n",
    "\n",
    "# Add basemap\n",
    "ctx.add_basemap(ax, crs=census_block_mercator.crs.to_string(), source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "ax.set_title('Buildings in Census Block 250173546012000')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "# Read unassigned buildings\n",
    "unassigned_buildings_path = \"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/unassigned_buildings.geojson\"\n",
    "unassigned_buildings_gdf = gpd.read_file(unassigned_buildings_path)\n",
    "\n",
    "# Read census blocks\n",
    "census_block_path = \"/Users/magic-rabbit/Documents/00_Tech-Repositories/05_MASTER_THESIS/SynGrid/syngrid/data_processor/output/MA/Middlesex_County/Cambridge_city/CENSUS/target_region_blocks.geojson\"\n",
    "census_blocks_gdf = gpd.read_file(census_block_path)\n",
    "\n",
    "# Convert to Web Mercator for contextily\n",
    "unassigned_buildings_mercator = unassigned_buildings_gdf.to_crs(epsg=3857)\n",
    "census_blocks_mercator = census_blocks_gdf.to_crs(epsg=3857)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "\n",
    "# Plot census blocks in opaque blue underneath\n",
    "census_blocks_mercator.plot(ax=ax, color='blue', alpha=0.3, edgecolor='darkblue', linewidth=0.5)\n",
    "\n",
    "# Plot unassigned buildings in red on top\n",
    "unassigned_buildings_mercator.plot(ax=ax, color='red', alpha=0.8, markersize=20)\n",
    "\n",
    "# Add basemap\n",
    "ctx.add_basemap(ax, crs=census_blocks_mercator.crs.to_string(), source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "ax.set_title(f'Unassigned Buildings ({len(unassigned_buildings_gdf)}) and Census Blocks', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total unassigned buildings: {len(unassigned_buildings_gdf)}\")\n",
    "print(f\"Total census blocks: {len(census_blocks_gdf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
